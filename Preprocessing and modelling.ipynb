{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n",
    "Loading the data, adding variables and removing not valide cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the load data \n",
    "\n",
    "df_load_raw = pd.read_csv(\n",
    "    \"consommation-quotidienne-brute.csv\",\n",
    "    sep=\";\",\n",
    "    nrows=100000,\n",
    ")\n",
    "df_load_raw.index = pd.to_datetime(df_load_raw[\"Date - Heure\"], utc=True)\n",
    "df_load_raw.rename(\n",
    "    columns={\n",
    "        \"Consommation brute électricité (MW) - RTE\": \"Historical_consumption\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Loading the temperature data  \n",
    "\n",
    "df_temperature_raw = pd.read_csv(\n",
    "    \"donnees-de-temperature-et-de-pseudo-rayonnement.csv\",\n",
    "    sep=\";\",\n",
    "    nrows=100000,\n",
    ")\n",
    "df_temperature_raw.index = pd.to_datetime(\n",
    "    df_temperature_raw[\"Horodate\"], utc=True\n",
    ")\n",
    "\n",
    "df_temperature_raw = df_temperature_raw.loc[\n",
    "    :, [\"Température réalisée lissée (°C)\", \"Pseudo rayonnement (%)\"]\n",
    "]\n",
    "df_temperature_raw.rename(\n",
    "    columns={\n",
    "        \"Température réalisée lissée (°C)\": \"Historical_temperature_smoothed\",\n",
    "        \"Pseudo rayonnement (%)\": \"Historical_irradiance\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "## Merging the two datasets and preliminary data viz\n",
    "\n",
    "df_load_temperature = df_load_raw.loc[:, [\"Historical_consumption\"]].merge(\n",
    "    df_temperature_raw, left_index=True, right_index=True\n",
    ")\n",
    "df_load_temperature = df_load_temperature.resample(\"H\").mean()\n",
    "# Adding more features\n",
    "df_load_temperature[\"day_of_week\"] = df_load_temperature.index.day_of_week\n",
    "df_load_temperature[\"month\"] = df_load_temperature.index.month\n",
    "df_load_temperature[\"day_of_year\"] = df_load_temperature.index.day_of_year\n",
    "df_load_temperature[\"day\"] = df_load_temperature.index.day\n",
    "df_load_temperature[\"timestamp\"] = df_load_temperature.index\n",
    "df_load_temperature[\"hour\"] = df_load_temperature.index.hour\n",
    "df_load_temperature[\"date\"] = df_load_temperature.index.date\n",
    "df_load_temperature[\n",
    "    \"weekday_or_week_end\"\n",
    "] = df_load_temperature.index.to_series().apply(\n",
    "    lambda x: \"weekend\" if x.day_of_week >= 5 else \"weekday\"\n",
    ")\n",
    "## Dropping COVID days\n",
    "\n",
    "df_load_temperature = df_load_temperature.loc[\n",
    "    df_load_temperature.index < \"2020-03-15\"\n",
    "]\n",
    "## Adding the French holidays\n",
    "## The library holidays provide such data\n",
    "\n",
    "import holidays\n",
    "\n",
    "dict_holidays = holidays.France(years=[2016, 2017, 2018, 2019, 2020])\n",
    "\n",
    "\n",
    "df_holidays = pd.DataFrame.from_dict(\n",
    "    dict_holidays, orient=\"index\", columns=[\"holiday\"]\n",
    ")\n",
    "df_holidays.index = pd.to_datetime(df_holidays.index)\n",
    "df_holidays[\"date\"] = df_holidays.index.date\n",
    "\n",
    "df_load_temperature_holidays = (\n",
    "    df_load_temperature.reset_index()\n",
    "    .merge(df_holidays, how=\"left\", on=\"date\")\n",
    "    .set_index(\"index\")\n",
    ")\n",
    "\n",
    "df_load_temperature_holidays[\"is_holiday\"] = df_load_temperature_holidays[\n",
    "    \"holiday\"\n",
    "].apply(lambda x: 1 if isinstance(x, str) else 0)\n",
    "\n",
    "## Aggregating the data to have daily temperatures accessible\n",
    "df_load_temperature_daily = df_load_temperature.resample(\"D\").mean()\n",
    "df_load_temperature_daily[\n",
    "    \"day_name\"\n",
    "] = df_load_temperature_daily.index.day_name()\n",
    "df_load_temperature_daily[\n",
    "    \"weekday_or_week_end\"\n",
    "] = df_load_temperature_daily.index.to_series().apply(\n",
    "    lambda x: \"weekend\" if x.day_of_week >= 5 else \"weekday\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeliing: Heka developed their own library, es privada je"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sia_ts_modelling (from versions: none)\n",
      "ERROR: No matching distribution found for sia_ts_modelling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\jimenaplastina\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\jimenaplastina\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jimenaplastina\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jimenaplastina\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jimenaplastina\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sia_ts_modelling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall sia_ts_modelling\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall scikit-learn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msia_ts_modelling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      9\u001b[0m (benchmarking_df, all_models, prediction_all_models,) \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     10\u001b[0m     input_df\u001b[38;5;241m=\u001b[39mdf_load_temperature_holidays\u001b[38;5;241m.\u001b[39mdropna(),\n\u001b[0;32m     11\u001b[0m     target_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHistorical_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     80\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sia_ts_modelling'"
     ]
    }
   ],
   "source": [
    "## We now import our library and perform the forecasting\n",
    "\n",
    "%pip install sia_ts_modelling\n",
    "%pip install scikit-learn\n",
    "from sia_ts_modelling.automate import pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "(benchmarking_df, all_models, prediction_all_models,) = pipeline(\n",
    "    input_df=df_load_temperature_holidays.dropna(),\n",
    "    target_column=\"Historical_consumption\",\n",
    "    features_sets={\n",
    "        \"temperature_only\": [\"Historical_temperature_smoothed\"],\n",
    "        \"temperature_day_month\": [\n",
    "            \"Historical_temperature_smoothed\",\n",
    "            \"day_of_week\",\n",
    "            \"month\",\n",
    "        ],\n",
    "        \"temperature_day_month_hour\": [\n",
    "            \"Historical_temperature_smoothed\",\n",
    "            \"hour\",\n",
    "            \"day_of_week\",\n",
    "            \"month\",\n",
    "        ],\n",
    "    },\n",
    "    model_and_init_params=[\n",
    "        {\n",
    "            \"name\": \"my_first_lasso\",\n",
    "            \"model\": \"lasso\",\n",
    "            \"features_sets\": [\"temperature_only\", \"temperature_day_month\"],\n",
    "            \"model_by_moment\": True,\n",
    "            \"period_moment\": \"hour\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"my_first_rf\",\n",
    "            \"model\": RandomForestRegressor,\n",
    "            \"features_sets\": [\"temperature_only\"],\n",
    "            \"kwargs_build\": {\"n_estimators\": 10},\n",
    "            \"model_by_moment\": True,\n",
    "            \"period_moment\": \"hour\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"my_first_gam\",\n",
    "            \"model\": \"gam\",\n",
    "            \"features_sets\": [\"temperature_day_month\"],\n",
    "            \"kwargs_build\": {\n",
    "                \"s_terms\": [\n",
    "                    {\n",
    "                        \"feature\": \"Historical_temperature_smoothed\",\n",
    "                        \"extra_kwargs\": {\"n_splines\": 13},\n",
    "                    },\n",
    "                ],\n",
    "                \"f_terms\": [\n",
    "                    {\n",
    "                        \"feature\": \"day_of_week\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"feature\": \"month\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "            \"model_by_moment\": True,\n",
    "            \"period_moment\": \"hour\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"aggregate_model\",\n",
    "            \"features_sets\": [\"temperature_day_month_hour\"],\n",
    "            \"model\": {\"my_lasso\": \"lasso\", \"my_rf\": RandomForestRegressor},\n",
    "            \"kwargs_build\": {\n",
    "                \"weights\": \"trained\",\n",
    "                \"my_rf\": {\"n_estimators\": 10},\n",
    "            },\n",
    "            \"model_by_moment\": False,\n",
    "            \"period_moment\": \"hour\",\n",
    "        },\n",
    "    ],\n",
    "    train_test_split_method=\"split_proportion\",\n",
    "    test_size=0.25,\n",
    "    metrics=[\"MAPE\", \"R2\", \"MSE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijo el modelo de GAM por tener menor MAPE en test\n",
    "\n",
    "Voy a calcular los shap values para entender como juega cada feature en resultado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# The background data is the training data used \n",
    "background = shap.maskers.Independent(\n",
    "    df_load_temperature_holidays[temperature_irradiance_day_year_holiday].dropna(),\n",
    "    max_samples=1000,\n",
    ")\n",
    "\n",
    "explainer_gam = shap.Explainer(my_gam_model.predict, background)\n",
    "\n",
    "# The shap values are computed below : 3000 values are sampled randomly to limit the computation time \n",
    "shap_values_gam = explainer_gam(\n",
    "    df_load_temperature_holidays[temperature_irradiance_day_year_holiday].dropna().sample(3000)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
